# -*- coding: utf-8 -*-
"""q1 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pRvrTKclG3OQ7Hk9QxGtBNmhIIi6mGDS
"""

!pip3 install torch
!pip3 install opencv-python
!pip3 install matplotlib
!pip3 install torchsummary
!pip3 install torchvision
!pip3 install pytorch_lightning
!pip3 install scikit-learn

import torch
import cv2
import numpy as np
import torch.nn as nn
from torchsummary import summary
from torchvision import datasets, transforms
from torch.utils.data import DataLoader as dataloader
from matplotlib import pyplot as plt

zip_path = '/content/drive/MyDrive/resources/Data.zip'
!rm -rf '/content/Data'
!cp '{zip_path}' '/content/data.zip'
!unzip -q 'data.zip'
!rm 'data.zip'

from google.colab import drive
drive.mount('/content/drive')

class AlexNet1(nn.Module): 
    def __init__(self, num_classes: int = 15) -> None: 
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=4, stride=4),
            nn.Flatten()
        )
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(96 * 14 * 14, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, num_classes)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

model = AlexNet1()
if torch.cuda.is_available():
  model.cuda()
summary(model, (3, 227, 227))

transform = transforms.Compose([
                                transforms.Resize((227, 227)),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5),
                                                     (0.5, 0.5, 0.5)),
                                transforms.RandomCrop((200, 200), padding=4),
                                transforms.RandomHorizontalFlip(),
                                transforms.Resize((227, 227))
                                ])
train_data = datasets.ImageFolder('/content/Data/Train', transform=transform)
train_loader = dataloader(train_data, batch_size=64, shuffle=True)
train_loader
test_data = datasets.ImageFolder('/content/Data/Test', transform=transform)
test_loader = dataloader(test_data, batch_size=64)

def batch_accuracy(yhat, k, labels):
  _, pred = torch.topk(yhat, k)
  cnt = 0 
  for i in range(k):
    cnt += (pred[:, i] == labels.cuda()).sum()
  return cnt.item()


def calc_model(model, epochs=40, name='MyNet', state = True): 
  global train_loader, test_loader
  loss_fn = nn.CrossEntropyLoss()
  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.1)
  train_losses = []
  test_losses = []
  accuracy = []
  accuracy_top5 =  []
  for epoch in range(epochs):
    train_epoch_loss = 0.0
    print("start epoch ", epoch)
    model.train() 
    for i, (images, labels) in enumerate(train_loader): 
      optimizer.zero_grad()
      yhat = model(images.cuda())
      loss = loss_fn(yhat, labels.cuda())
      train_epoch_loss += loss.item() 
      loss.backward()
      optimizer.step()
    train_epoch_loss /= len(train_loader)
    train_losses.append(train_epoch_loss)
    print("train loss: ", train_epoch_loss)


    test_epoch_loss = 0
    model.eval()
    acc = 0
    acc5 = 0
    all_count = 0
    for i, (images, labels) in enumerate(test_loader): 
      yhat = model(images.cuda())
      loss = loss_fn(yhat, labels.cuda())
      test_epoch_loss += loss.item()

      batch_size = labels.size(0)
      all_count += batch_size
      acc += batch_accuracy(yhat, 1, labels)
      acc5 += batch_accuracy(yhat, 5, labels)

    acc = (acc / all_count) * 100
    acc5 = (acc5 / all_count) * 100

    accuracy.append(acc)
    accuracy_top5.append(acc)

    test_epoch_loss /= len(test_loader)
    test_losses.append(test_epoch_loss)
    print("test loss: ", test_epoch_loss, " accuracy: ", acc, " accuracy5: ", acc5)

  if state == True: 
    epochs_list = [i for i in range(epochs)]
    plt.plot(epochs_list, train_losses, label='train')
    plt.plot(epochs_list, test_losses, label='test')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.savefig(name + '_loss')
    plt.clf()

    plt.plot(epochs_list, accuracy)
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.savefig(name + '_accuracy')
    plt.clf()

    plt.plot(epochs_list, accuracy_top5)
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.savefig(name + '_accuracy5')
    plt.clf()



def calc(MyNet, epochs = 40, name = 'MyNet', state = True):
  model = MyNet()
  if torch.cuda.is_available():
    model.cuda()
  calc_model(model, epochs, name, state)

class AlexNet2(nn.Module): 
    def __init__(self, num_classes: int = 15) -> None: 
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=4, stride=2),
            nn.Conv2d(96, 256, kernel_size=5, padding=2, stride=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),
            nn.ReLU(inplace=True),
            nn.Flatten(),
        )
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(43264, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

model = AlexNet2()
if torch.cuda.is_available():
  model.cuda()
summary(model, (3, 227, 227))

class AlexNet3(nn.Module): 
    def __init__(self, num_classes: int = 15) -> None: 
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=4, stride=2),
            nn.Conv2d(96, 256, kernel_size=5, padding=2, stride=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(256, 384, kernel_size=3, padding=1, stride=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 384, kernel_size=3, padding=1, stride=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1, stride=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Flatten(),
        )
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(9216, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

model = AlexNet3()
if torch.cuda.is_available():
  model.cuda()
summary(model, (3, 227, 227))

calc(AlexNet3, 60)

import torchvision
model = torchvision.models.alexnet(pretrained=True)
for param in model.parameters(): 
  param.requires_grad = False
model.classifier = nn.Sequential(
    *[model.classifier[i] for i in range(6)],
    nn.Linear(4096, 15, bias=True)
    )
print(model)
if torch.cuda.is_available():
  model.cuda()
calc_model(model, 70, 'AlexNet4')

import torchvision
model = torchvision.models.alexnet(pretrained=True)
for param in model.parameters(): 
  param.requires_grad = False
model.classifier = nn.Sequential(
    *[model.classifier[i] for i in range(6)],
    nn.Linear(4096, 15, bias=True)
    )
print(model)
if torch.cuda.is_available():
  model.cuda()
calc_model(model, 5, 'AlexNet5', False)
for param in model.parameters():
  param.requires_grad = True
calc_model(model, 10, 'AlexNet5')

calc(AlexNet1, 100, 'AlexNet1')

calc(AlexNet2, 100, 'AlexNet2')

calc(AlexNet3, 150, 'AlexNet3')